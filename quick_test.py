#!/usr/bin/env python3
"""
å¿«é€Ÿæ€§èƒ½æ¸¬è©¦è…³æœ¬ - åªæ¸¬è©¦å°‘é‡æ–‡ç« 
"""

import asyncio
import time
import logging
from datetime import datetime
from crawl_orchestrator import CrawlOrchestrator
from database import DatabaseManager
from models import PTTArticle

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s'
)
logger = logging.getLogger(__name__)

async def quick_test():
    """å¿«é€Ÿæ¸¬è©¦ - åªçˆ¬å–å’Œåˆ†æå°‘é‡æ–‡ç« """
    logger.info("ğŸš€ é–‹å§‹å¿«é€Ÿæ€§èƒ½æ¸¬è©¦...")
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()
    start_datetime = datetime.now()
    
    # åˆå§‹åŒ–
    db_manager = DatabaseManager()
    orchestrator = CrawlOrchestrator()
    
    # æ¸…ç†æ¸¬è©¦æ•¸æ“š
    logger.info("æ¸…ç†æ¸¬è©¦æ•¸æ“š...")
    with db_manager.get_session() as session:
        session.query(PTTArticle).delete()
        session.commit()
    
    # ç²å–åˆå§‹çµ±è¨ˆ
    with db_manager.get_session() as session:
        initial_count = session.query(PTTArticle).count()
    
    logger.info(f"åˆå§‹æ–‡ç« æ•¸: {initial_count}")
    
    try:
        # é‹è¡Œçˆ¬èŸ²å’Œåˆ†æ
        logger.info("é–‹å§‹çˆ¬èŸ²å’Œåˆ†æ...")
        crawl_start = time.time()
        
        await orchestrator.run_crawl_session()
        
        crawl_end = time.time()
        crawl_duration = crawl_end - crawl_start
        
        # ç²å–æœ€çµ‚çµ±è¨ˆ
        with db_manager.get_session() as session:
            final_count = session.query(PTTArticle).count()
            analyzed_count = session.query(PTTArticle).filter(PTTArticle.is_analyzed == True).count()
        
        # è¨ˆç®—ç¸½è€—æ™‚
        total_duration = time.time() - start_time
        
        # ç”Ÿæˆå ±å‘Š
        new_articles = final_count - initial_count
        avg_time_per_article = crawl_duration / new_articles if new_articles > 0 else 0
        
        print("\n" + "="*50)
        print("ğŸ“Š å¿«é€Ÿæ€§èƒ½æ¸¬è©¦å ±å‘Š")
        print("="*50)
        print(f"ğŸ• é–‹å§‹æ™‚é–“: {start_datetime.strftime('%H:%M:%S')}")
        print(f"â±ï¸  ç¸½è€—æ™‚: {int(total_duration // 60)}åˆ†{int(total_duration % 60)}ç§’")
        print(f"ğŸ•·ï¸  çˆ¬èŸ²+åˆ†æè€—æ™‚: {int(crawl_duration // 60)}åˆ†{int(crawl_duration % 60)}ç§’")
        print(f"ğŸ“ˆ æ–°å¢æ–‡ç« æ•¸: {new_articles}")
        print(f"ğŸ“ˆ å·²åˆ†ææ–‡ç« æ•¸: {analyzed_count}")
        print(f"âš¡ å¹³å‡æ¯ç¯‡æ–‡ç« : {avg_time_per_article:.2f} ç§’")
        print(f"ğŸ“Š åˆ†ææˆåŠŸç‡: {(analyzed_count/new_articles*100):.1f}%" if new_articles > 0 else "ğŸ“Š åˆ†ææˆåŠŸç‡: N/A")
        print("="*50)
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(quick_test())
