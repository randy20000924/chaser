#!/usr/bin/env python3
"""æ–‡ç« åˆ†ææ¨¡çµ„ - åˆ†æPTTæ–‡ç« ä¸­çš„æŠ•è³‡æ¨™çš„å’Œç­–ç•¥."""

import re
import json
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from loguru import logger
from database import db_manager
from models import PTTArticle
from sqlalchemy import desc


class ArticleAnalyzer:
    """æ–‡ç« åˆ†æå™¨."""
    
    def __init__(self):
        self.stock_patterns = {
            # ç¾è‚¡ä»£ç¢¼ (1-5å€‹å­—æ¯)
            'us_stocks': r'\b([A-Z]{1,5})\b',
            # å°è‚¡ä»£ç¢¼ (4ä½æ•¸å­—)
            'tw_stocks': r'\b([0-9]{4})\b',
            # æ¸¯è‚¡ä»£ç¢¼ (4-5ä½æ•¸å­—)
            'hk_stocks': r'\b([0-9]{4,5})\b'
        }
        
        # æŠ•è³‡ç­–ç•¥é—œéµè©
        self.strategy_keywords = {
            'buy_signals': ['è²·', 'å¤š', 'çœ‹å¤š', 'æ¨è–¦', 'å»ºè­°', 'å»ºå€‰', 'åŠ å€‰', 'æŒæœ‰'],
            'sell_signals': ['è³£', 'ç©º', 'çœ‹ç©º', 'æ¸›å€‰', 'å‡ºå ´', 'ç²åˆ©äº†çµ'],
            'risk_keywords': ['é¢¨éšª', 'æ³¨æ„', 'å°å¿ƒ', 'è¬¹æ…', 'æ³¢å‹•', 'ä¸ç¢ºå®š'],
            'sector_keywords': ['åŠå°é«”', 'AI', 'é›»å‹•è»Š', 'æ–°èƒ½æº', 'ç”ŸæŠ€', 'é‡‘è', 'åœ°ç”¢']
        }
    
    def analyze_article(self, article_id: str) -> Dict:
        """åˆ†æå–®ç¯‡æ–‡ç« ."""
        with db_manager.get_session() as session:
            article = session.query(PTTArticle).filter(
                PTTArticle.article_id == article_id
            ).first()
            
            if not article:
                return {"error": "æ–‡ç« ä¸å­˜åœ¨"}
            
            return self._analyze_content(article)
    
    def analyze_article_by_url(self, url: str) -> Dict:
        """æ ¹æ“šURLåˆ†ææ–‡ç« ."""
        with db_manager.get_session() as session:
            article = session.query(PTTArticle).filter(
                PTTArticle.url == url
            ).first()
            
            if not article:
                return {"error": "æ–‡ç« ä¸å­˜åœ¨"}
            
            return self._analyze_content(article)
    
    def _analyze_content(self, article: PTTArticle) -> Dict:
        """åˆ†ææ–‡ç« å…§å®¹."""
        content = article.content
        title = article.title
        
        # æå–è‚¡ç¥¨ä»£ç¢¼
        stocks = self._extract_stocks(content)
        
        # åˆ†ææŠ•è³‡ç­–ç•¥
        strategy = self._analyze_strategy(content)
        
        # åˆ†ææƒ…æ„Ÿå‚¾å‘
        sentiment = self._analyze_sentiment(content)
        
        # åˆ†æç”¢æ¥­é¡åˆ¥
        sectors = self._analyze_sectors(content)
        
        # åˆ†ææŠ•è³‡å»ºè­°
        recommendations = self._extract_recommendations(content)
        
        # åˆ†æé¢¨éšªæç¤º
        risks = self._extract_risks(content)
        
        return {
            "article_id": article.article_id,
            "title": article.title,
            "author": article.author,
            "publish_time": article.publish_time.isoformat(),
            "url": article.url,
            "push_count": article.push_count,
            "analysis": {
                "stocks": stocks,
                "strategy": strategy,
                "sentiment": sentiment,
                "sectors": sectors,
                "recommendations": recommendations,
                "risks": risks,
                "investment_thesis": self._extract_investment_thesis(content),
                "price_targets": self._extract_price_targets(content),
                "time_horizon": self._analyze_time_horizon(content)
            }
        }
    
    def _extract_stocks(self, content: str) -> Dict:
        """æå–è‚¡ç¥¨ä»£ç¢¼."""
        stocks = {
            "us_stocks": [],
            "tw_stocks": [],
            "hk_stocks": [],
            "mentioned_stocks": []
        }
        
        # æå–ç¾è‚¡ä»£ç¢¼
        us_matches = re.findall(self.stock_patterns['us_stocks'], content)
        stocks["us_stocks"] = list(set([match for match in us_matches if len(match) <= 5]))
        
        # æå–å°è‚¡ä»£ç¢¼
        tw_matches = re.findall(self.stock_patterns['tw_stocks'], content)
        stocks["tw_stocks"] = list(set([match for match in tw_matches if not match.startswith(('20', '19', '0', '1'))]))
        
        # æå–æ¸¯è‚¡ä»£ç¢¼
        hk_matches = re.findall(self.stock_patterns['hk_stocks'], content)
        stocks["hk_stocks"] = list(set([match for match in hk_matches if len(match) >= 4]))
        
        # åˆä½µæ‰€æœ‰è‚¡ç¥¨
        all_stocks = stocks["us_stocks"] + stocks["tw_stocks"] + stocks["hk_stocks"]
        stocks["mentioned_stocks"] = list(set(all_stocks))
        
        return stocks
    
    def _analyze_strategy(self, content: str) -> Dict:
        """åˆ†ææŠ•è³‡ç­–ç•¥."""
        strategy = {
            "buy_signals": [],
            "sell_signals": [],
            "strategy_type": "unknown"
        }
        
        # æª¢æŸ¥è²·å…¥ä¿¡è™Ÿ
        for keyword in self.strategy_keywords['buy_signals']:
            if keyword in content:
                strategy["buy_signals"].append(keyword)
        
        # æª¢æŸ¥è³£å‡ºä¿¡è™Ÿ
        for keyword in self.strategy_keywords['sell_signals']:
            if keyword in content:
                strategy["sell_signals"].append(keyword)
        
        # åˆ¤æ–·ç­–ç•¥é¡å‹
        if strategy["buy_signals"] and not strategy["sell_signals"]:
            strategy["strategy_type"] = "bullish"
        elif strategy["sell_signals"] and not strategy["buy_signals"]:
            strategy["strategy_type"] = "bearish"
        elif strategy["buy_signals"] and strategy["sell_signals"]:
            strategy["strategy_type"] = "mixed"
        
        return strategy
    
    def _analyze_sentiment(self, content: str) -> Dict:
        """åˆ†ææƒ…æ„Ÿå‚¾å‘."""
        positive_words = ['çœ‹å¥½', 'æ¨‚è§€', 'æˆé•·', 'æ©Ÿæœƒ', 'æ½›åŠ›', 'åˆ©å¤š', 'ä¸Šæ¼²', 'çªç ´']
        negative_words = ['çœ‹å£', 'æ‚²è§€', 'è¡°é€€', 'é¢¨éšª', 'åˆ©ç©º', 'ä¸‹è·Œ', 'ç ´åº•']
        
        positive_count = sum(1 for word in positive_words if word in content)
        negative_count = sum(1 for word in negative_words if word in content)
        
        if positive_count > negative_count:
            sentiment = "positive"
        elif negative_count > positive_count:
            sentiment = "negative"
        else:
            sentiment = "neutral"
        
        return {
            "sentiment": sentiment,
            "positive_score": positive_count,
            "negative_score": negative_count,
            "confidence": abs(positive_count - negative_count) / max(positive_count + negative_count, 1)
        }
    
    def _analyze_sectors(self, content: str) -> List[str]:
        """åˆ†æç”¢æ¥­é¡åˆ¥."""
        sectors = []
        for sector in self.strategy_keywords['sector_keywords']:
            if sector in content:
                sectors.append(sector)
        
        # é¡å¤–çš„ç”¢æ¥­è­˜åˆ¥
        if 'åŠå°é«”' in content or 'æ™¶ç‰‡' in content or 'AMD' in content or 'NV' in content:
            sectors.append('åŠå°é«”')
        if 'AI' in content or 'äººå·¥æ™ºæ…§' in content:
            sectors.append('AI')
        if 'é›»å‹•è»Š' in content or 'ç‰¹æ–¯æ‹‰' in content or 'TSLA' in content:
            sectors.append('é›»å‹•è»Š')
        if 'æ–°èƒ½æº' in content or 'å¤ªé™½èƒ½' in content or 'é¢¨é›»' in content:
            sectors.append('æ–°èƒ½æº')
        if 'ç”ŸæŠ€' in content or 'é†«ç™‚' in content or 'è£½è—¥' in content:
            sectors.append('ç”ŸæŠ€')
        if 'è¡›æ˜Ÿ' in content or 'å¤ªç©º' in content or 'SpaceX' in content:
            sectors.append('å¤ªç©ºç§‘æŠ€')
        if 'æ ¸èƒ½' in content or 'æ ¸é›»' in content:
            sectors.append('æ ¸èƒ½')
        
        return list(set(sectors))
    
    def _extract_recommendations(self, content: str) -> List[Dict]:
        """æå–æŠ•è³‡å»ºè­°."""
        recommendations = []
        
        # å°‹æ‰¾åƒ¹æ ¼å»ºè­°
        price_patterns = [
            r'(\d+(?:\.\d+)?)\s*å…ƒ',
            r'(\d+(?:\.\d+)?)\s*ç¾å…ƒ',
            r'(\d+(?:\.\d+)?)\s*USD'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                recommendations.append({
                    "type": "price_target",
                    "value": float(match),
                    "context": "åƒ¹æ ¼ç›®æ¨™"
                })
        
        # å°‹æ‰¾æ™‚é–“å»ºè­°
        time_patterns = [
            r'(\d+)\s*å¹´',
            r'(\d+)\s*æœˆ',
            r'(\d+)\s*å­£'
        ]
        
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                recommendations.append({
                    "type": "time_horizon",
                    "value": int(match),
                    "context": "æŠ•è³‡æœŸé–“"
                })
        
        return recommendations
    
    def _extract_risks(self, content: str) -> List[str]:
        """æå–é¢¨éšªæç¤º."""
        risks = []
        
        risk_indicators = [
            'é¢¨éšª', 'æ³¨æ„', 'å°å¿ƒ', 'è¬¹æ…', 'æ³¢å‹•', 'ä¸ç¢ºå®š', 'å¯èƒ½', 'æˆ–è¨±',
            'ä½†æ˜¯', 'ä¸é', 'ç„¶è€Œ', 'é›–ç„¶', 'å„˜ç®¡'
        ]
        
        for indicator in risk_indicators:
            if indicator in content:
                risks.append(indicator)
        
        return list(set(risks))
    
    def _extract_investment_thesis(self, content: str) -> str:
        """æå–æŠ•è³‡è«–è¿°."""
        # å°‹æ‰¾é—œéµè«–è¿°æ®µè½
        thesis_indicators = ['å› ç‚º', 'æ‰€ä»¥', 'å› æ­¤', 'ç”±æ–¼', 'åŸºæ–¼', 'æ ¹æ“š']
        
        for indicator in thesis_indicators:
            if indicator in content:
                # æå–åŒ…å«è©²æŒ‡ç¤ºè©çš„å¥å­
                sentences = content.split('ã€‚')
                for sentence in sentences:
                    if indicator in sentence:
                        return sentence.strip()
        
        return "æœªæ‰¾åˆ°æ˜ç¢ºæŠ•è³‡è«–è¿°"
    
    def _extract_price_targets(self, content: str) -> List[Dict]:
        """æå–åƒ¹æ ¼ç›®æ¨™."""
        price_targets = []
        
        # å°‹æ‰¾åƒ¹æ ¼ç›®æ¨™æ¨¡å¼
        patterns = [
            r'ç›®æ¨™åƒ¹\s*(\d+(?:\.\d+)?)',
            r'çœ‹åˆ°\s*(\d+(?:\.\d+)?)',
            r'ä¸Šçœ‹\s*(\d+(?:\.\d+)?)',
            r'(\d+(?:\.\d+)?)\s*å…ƒ'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                price_targets.append({
                    "price": float(match),
                    "context": "åƒ¹æ ¼ç›®æ¨™"
                })
        
        return price_targets
    
    def _analyze_time_horizon(self, content: str) -> str:
        """åˆ†ææŠ•è³‡æ™‚é–“æ¡†æ¶."""
        if any(word in content for word in ['çŸ­æœŸ', 'è¿‘æœŸ', 'é€™é€±', 'é€™å€‹æœˆ']):
            return "çŸ­æœŸ"
        elif any(word in content for word in ['ä¸­æœŸ', 'å¹¾å€‹æœˆ', 'åŠå¹´']):
            return "ä¸­æœŸ"
        elif any(word in content for word in ['é•·æœŸ', 'å¹¾å¹´', 'é•·æœŸæŒæœ‰']):
            return "é•·æœŸ"
        else:
            return "æœªæ˜ç¢º"
    
    def batch_analyze_articles(self, author: str = None, limit: int = 10) -> List[Dict]:
        """æ‰¹é‡åˆ†ææ–‡ç« ."""
        with db_manager.get_session() as session:
            query = session.query(PTTArticle)
            
            if author:
                query = query.filter(PTTArticle.author == author)
            
            articles = query.order_by(desc(PTTArticle.publish_time)).limit(limit).all()
            
            results = []
            for article in articles:
                try:
                    analysis = self._analyze_content(article)
                    results.append(analysis)
                except Exception as e:
                    logger.error(f"åˆ†ææ–‡ç«  {article.article_id} å¤±æ•—: {e}")
                    continue
            
            return results
    
    def get_author_investment_profile(self, author: str) -> Dict:
        """åˆ†æä½œè€…æŠ•è³‡åå¥½."""
        with db_manager.get_session() as session:
            articles = session.query(PTTArticle).filter(
                PTTArticle.author == author
            ).order_by(desc(PTTArticle.publish_time)).all()
            
            if not articles:
                return {"error": "æ‰¾ä¸åˆ°è©²ä½œè€…çš„æ–‡ç« "}
            
            # çµ±è¨ˆåˆ†æ
            all_stocks = []
            all_sectors = []
            all_sentiments = []
            
            for article in articles:
                analysis = self._analyze_content(article)
                all_stocks.extend(analysis["analysis"]["stocks"]["mentioned_stocks"])
                all_sectors.extend(analysis["analysis"]["sectors"])
                all_sentiments.append(analysis["analysis"]["sentiment"]["sentiment"])
            
            # è¨ˆç®—çµ±è¨ˆ
            stock_frequency = {}
            for stock in all_stocks:
                stock_frequency[stock] = stock_frequency.get(stock, 0) + 1
            
            sector_frequency = {}
            for sector in all_sectors:
                sector_frequency[sector] = sector_frequency.get(sector, 0) + 1
            
            sentiment_frequency = {}
            for sentiment in all_sentiments:
                sentiment_frequency[sentiment] = sentiment_frequency.get(sentiment, 0) + 1
            
            return {
                "author": author,
                "total_articles": len(articles),
                "favorite_stocks": sorted(stock_frequency.items(), key=lambda x: x[1], reverse=True)[:10],
                "favorite_sectors": sorted(sector_frequency.items(), key=lambda x: x[1], reverse=True)[:5],
                "sentiment_distribution": sentiment_frequency,
                "investment_style": self._determine_investment_style(all_sectors, all_sentiments)
            }
    
    def _determine_investment_style(self, sectors: List[str], sentiments: List[str]) -> str:
        """åˆ¤æ–·æŠ•è³‡é¢¨æ ¼."""
        if 'åŠå°é«”' in sectors and 'AI' in sectors:
            return "ç§‘æŠ€æˆé•·å‹"
        elif 'æ–°èƒ½æº' in sectors and 'æ ¸èƒ½' in sectors:
            return "èƒ½æºè½‰å‹å‹"
        elif 'å¤ªç©ºç§‘æŠ€' in sectors:
            return "å‰æ²¿ç§‘æŠ€å‹"
        elif sentiments.count('positive') > sentiments.count('negative'):
            return "æ¨‚è§€é€²å–å‹"
        else:
            return "ç©©å¥ä¿å®ˆå‹"


def main():
    """æ¸¬è©¦åˆ†æåŠŸèƒ½."""
    analyzer = ArticleAnalyzer()
    
    # åˆ†æç‰¹å®šæ–‡ç« 
    print("ğŸ” åˆ†æ mrp çš„æœ€æ–°æ–‡ç« ...")
    analysis = analyzer.analyze_article_by_url("https://www.ptt.cc/bbs/Stock/M.1759822323.A.E44.html")
    
    if "error" not in analysis:
        print(f"ğŸ“° æ–‡ç« : {analysis['title']}")
        print(f"ä½œè€…: {analysis['author']}")
        print(f"æ¨æ–‡æ•¸: {analysis['push_count']}")
        print()
        
        print("ğŸ“Š åˆ†æçµæœ:")
        print(f"è‚¡ç¥¨ä»£ç¢¼: {analysis['analysis']['stocks']['mentioned_stocks']}")
        print(f"æŠ•è³‡ç­–ç•¥: {analysis['analysis']['strategy']['strategy_type']}")
        print(f"æƒ…æ„Ÿå‚¾å‘: {analysis['analysis']['sentiment']['sentiment']}")
        print(f"ç”¢æ¥­é¡åˆ¥: {analysis['analysis']['sectors']}")
        print(f"æŠ•è³‡å»ºè­°: {len(analysis['analysis']['recommendations'])} é …")
        print(f"é¢¨éšªæç¤º: {analysis['analysis']['risks']}")
        print(f"æŠ•è³‡è«–è¿°: {analysis['analysis']['investment_thesis']}")
        print(f"æ™‚é–“æ¡†æ¶: {analysis['analysis']['time_horizon']}")
    
    # åˆ†æä½œè€…æŠ•è³‡åå¥½
    print("\nğŸ‘¤ åˆ†æ mrp çš„æŠ•è³‡åå¥½...")
    profile = analyzer.get_author_investment_profile("mrp")
    
    if "error" not in profile:
        print(f"ç¸½æ–‡ç« æ•¸: {profile['total_articles']}")
        print(f"åå¥½è‚¡ç¥¨: {profile['favorite_stocks'][:5]}")
        print(f"åå¥½ç”¢æ¥­: {profile['favorite_sectors']}")
        print(f"æƒ…æ„Ÿåˆ†å¸ƒ: {profile['sentiment_distribution']}")
        print(f"æŠ•è³‡é¢¨æ ¼: {profile['investment_style']}")


if __name__ == "__main__":
    main()
